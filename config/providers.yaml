# Model Optimizer - Provider Configuration
# ========================================

providers:
  # Anthropic Claude models
  anthropic:
    api_key_env: "ANTHROPIC_API_KEY"
    models:
      haiku:
        id: "claude-3-haiku-20240307"
        input_cost_per_mtok: 0.25
        output_cost_per_mtok: 1.25
        max_tokens: 4096
        context_window: 200000

      sonnet:
        id: "claude-sonnet-4-20250514"
        input_cost_per_mtok: 3.0
        output_cost_per_mtok: 15.0
        max_tokens: 8192
        context_window: 200000

      opus:
        id: "claude-opus-4-5-20251101"
        input_cost_per_mtok: 15.0
        output_cost_per_mtok: 75.0
        max_tokens: 8192
        context_window: 200000

  # ZhipuAI GLM models (optional)
  zhipu:
    base_url: "https://open.bigmodel.cn/api/paas/v4"
    api_key_env: "ZHIPU_API_KEY"
    models:
      glm-4-6:
        id: "glm-4"
        input_cost_per_mtok: 0.6
        output_cost_per_mtok: 2.2
        max_tokens: 8192
        context_window: 128000

      glm-4-7:
        id: "glm-4-plus"
        input_cost_per_mtok: 0.6
        output_cost_per_mtok: 2.2
        max_tokens: 128000
        context_window: 200000

# Default configuration
defaults:
  provider: "anthropic"
  strategy: "2-tier"

  tier_models:
    # 2-tier strategy: primary for daily tasks, critical for important decisions
    2-tier:
      primary: "anthropic:sonnet"
      critical: "anthropic:opus"

    # 3-tier strategy: tier1 for exploration, tier2 for implementation, tier3 for architecture
    3-tier:
      tier1: "anthropic:haiku"
      tier2: "anthropic:sonnet"
      tier3: "anthropic:opus"
